{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d597da-08b5-4ec2-b0eb-2d2b76d3130a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:47.225481Z",
     "iopub.status.busy": "2021-11-30T16:42:47.224884Z",
     "iopub.status.idle": "2021-11-30T16:42:51.808539Z",
     "shell.execute_reply": "2021-11-30T16:42:51.807757Z",
     "shell.execute_reply.started": "2021-11-30T16:42:47.225362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric\n",
    "from torch import logical_and, logical_or, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5281f0f3-657d-49c7-9805-04861b1bfa0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:51.810029Z",
     "iopub.status.busy": "2021-11-30T16:42:51.809592Z",
     "iopub.status.idle": "2021-11-30T16:42:52.929104Z",
     "shell.execute_reply": "2021-11-30T16:42:52.928415Z",
     "shell.execute_reply.started": "2021-11-30T16:42:51.810000Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and nest genres\n",
    "df = pd.read_csv(\"data/df_fixed.csv\")\n",
    "df_genres = pd.read_csv(\"data/df_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a5e173-c689-4015-81a5-78bb399b2dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:52.931301Z",
     "iopub.status.busy": "2021-11-30T16:42:52.931080Z",
     "iopub.status.idle": "2021-11-30T16:42:52.959616Z",
     "shell.execute_reply": "2021-11-30T16:42:52.959005Z",
     "shell.execute_reply.started": "2021-11-30T16:42:52.931272Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only keep the top 30 genres\n",
    "top_genres = (\n",
    "    df_genres.query(\"Genre != 'unknown'\")\n",
    "    .groupby(\"Genre\")\n",
    "    .agg(n=(\"Genre\", \"count\"))\n",
    "    .reset_index()\n",
    "    .sort_values(\"n\", ascending=False)\n",
    "    .head(30)\n",
    "    .Genre.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b13b3e5-3e8f-429d-abb1-6a4a23a1bee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:52.960729Z",
     "iopub.status.busy": "2021-11-30T16:42:52.960477Z",
     "iopub.status.idle": "2021-11-30T16:42:53.120377Z",
     "shell.execute_reply": "2021-11-30T16:42:53.119681Z",
     "shell.execute_reply.started": "2021-11-30T16:42:52.960701Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode genre labels to wide arrays\n",
    "df_genres = (\n",
    "    df_genres.query(\"Genre in @top_genres\")\n",
    "    .assign(cnt=1)\n",
    "    .pivot_table(index=[\"movieID\"], columns=\"Genre\", values=[\"cnt\"])\n",
    "    .fillna(0)\n",
    "    # .astype(int)\n",
    "    .reset_index(col_level=1)  # get movieID out\n",
    ")\n",
    "\n",
    "df_genres.columns = [x[1] for x in df_genres.columns]\n",
    "df_genres = df_genres.set_index(\"movieID\")\n",
    "\n",
    "genre_names = df_genres.columns.tolist()\n",
    "labels = df_genres.values.tolist()\n",
    "df_genres = pd.DataFrame({\"movieID\": df_genres.index, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab835c8-ce1f-48a6-8032-e50f90c0e28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:53.121641Z",
     "iopub.status.busy": "2021-11-30T16:42:53.121425Z",
     "iopub.status.idle": "2021-11-30T16:42:53.184381Z",
     "shell.execute_reply": "2021-11-30T16:42:53.183746Z",
     "shell.execute_reply.started": "2021-11-30T16:42:53.121612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>11891</td>\n",
       "      <td>David Greene (Brendan Fraser) is a working-cla...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>6514</td>\n",
       "      <td>An old friend of the boys returns to town and ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27658</th>\n",
       "      <td>33949</td>\n",
       "      <td>In 1995, five mysterious murders took place. I...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>4658</td>\n",
       "      <td>Ross McEwen pulls an unusual bank job in the N...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>17210</td>\n",
       "      <td>The film begins with a getaway driver waiting ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27432</th>\n",
       "      <td>33660</td>\n",
       "      <td>Hikaru Oshiro, noticing that there was a lack ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15541</th>\n",
       "      <td>16212</td>\n",
       "      <td>In a high tech underground facility, senior te...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>25266</td>\n",
       "      <td>Shankar's (Amitabh Bachchan) father, who is a ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22113</th>\n",
       "      <td>24096</td>\n",
       "      <td>Biren Dutta is a lawyer. He is unsuccessful in...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>11315</td>\n",
       "      <td>Eddie Dodd is a burnt-out attorney who has lef...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieID                                               Plot  \\\n",
       "11327    11891  David Greene (Brendan Fraser) is a working-cla...   \n",
       "6303      6514  An old friend of the boys returns to town and ...   \n",
       "27658    33949  In 1995, five mysterious murders took place. I...   \n",
       "4481      4658  Ross McEwen pulls an unusual bank job in the N...   \n",
       "16465    17210  The film begins with a getaway driver waiting ...   \n",
       "27432    33660  Hikaru Oshiro, noticing that there was a lack ...   \n",
       "15541    16212  In a high tech underground facility, senior te...   \n",
       "22958    25266  Shankar's (Amitabh Bachchan) father, who is a ...   \n",
       "22113    24096  Biren Dutta is a lawyer. He is unsuccessful in...   \n",
       "10774    11315  Eddie Dodd is a burnt-out attorney who has lef...   \n",
       "\n",
       "                                                  labels  \n",
       "11327  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "6303   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "27658  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "4481   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "16465  [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "27432  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "15541  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "22958  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "22113  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "10774  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.reset_index()\n",
    "    .rename(columns={\"index\": \"movieID\"})\n",
    "    .filter([\"movieID\", \"Plot\"])\n",
    "    .merge(df_genres, on=\"movieID\")\n",
    ")\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639006f-5c09-44eb-a446-3af9a77c9684",
   "metadata": {},
   "source": [
    "## Multi-label classification\n",
    "\n",
    "Recall what our goal was: to predict the genres of movies based on the movie plots. We can do this by using a multi-label classifier, such as `sklearn.ensemble.RandomForestClassifier`. But before getting into the modeling, we need to construct a dataset that can be used by the classifier, i.e. break down the plot text into features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad553cfe-57cd-45ef-98c8-acc26f3b1e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:42:53.185589Z",
     "iopub.status.busy": "2021-11-30T16:42:53.185374Z",
     "iopub.status.idle": "2021-11-30T16:43:04.740526Z",
     "shell.execute_reply": "2021-11-30T16:43:04.739836Z",
     "shell.execute_reply.started": "2021-11-30T16:42:53.185561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a8eb9a275e4f51b23810b7dac2ab75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configurations\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "batch_size = 8\n",
    "num_labels = len(genre_names)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Construct dataset\n",
    "dat = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize the Plot column\n",
    "dat = dat.map(\n",
    "    lambda batch: tokenizer.batch_encode_plus(\n",
    "        batch[\"Plot\"], padding=\"max_length\", truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=[\"Plot\", \"__index_level_0__\", \"movieID\"],\n",
    ")\n",
    "\n",
    "# Retrieve tensors of the following columns as model inputs\n",
    "valid_cols = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    "cols = [c for c in dat.column_names if c in valid_cols]\n",
    "dat.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "# Train/validation/test split\n",
    "dat = dat.train_test_split(test_size=test_ratio, seed=42)\n",
    "dat_train = dat[\"train\"].train_test_split(test_size=val_ratio, seed=42)\n",
    "dat[\"train\"] = dat_train[\"train\"]\n",
    "dat[\"validation\"] = dat_train[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b5e30b-3023-4ffa-9c8c-9f323f9a4343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:43:04.742061Z",
     "iopub.status.busy": "2021-11-30T16:43:04.741828Z",
     "iopub.status.idle": "2021-11-30T16:43:10.694044Z",
     "shell.execute_reply": "2021-11-30T16:43:10.693199Z",
     "shell.execute_reply.started": "2021-11-30T16:43:04.742030Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=30, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify last layer of model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.classifier = nn.Linear(768, num_labels)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ecf802d-b150-46cb-97a1-8e5513de9014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:43:10.695784Z",
     "iopub.status.busy": "2021-11-30T16:43:10.695468Z",
     "iopub.status.idle": "2021-11-30T16:43:10.702722Z",
     "shell.execute_reply": "2021-11-30T16:43:10.702145Z",
     "shell.execute_reply.started": "2021-11-30T16:43:10.695751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert_multilabel\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    label_names=genre_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074894a7-27ba-461a-a3b0-961c997f64b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T16:43:10.703859Z",
     "iopub.status.busy": "2021-11-30T16:43:10.703593Z",
     "iopub.status.idle": "2021-11-30T17:35:35.389379Z",
     "shell.execute_reply": "2021-11-30T17:35:35.388758Z",
     "shell.execute_reply.started": "2021-11-30T16:43:10.703821Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 22704\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9460\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9460' max='9460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9460/9460 52:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-946\n",
      "Configuration saved in distilbert_multilabel/checkpoint-946/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-946/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-1892\n",
      "Configuration saved in distilbert_multilabel/checkpoint-1892/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-1892/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-2838\n",
      "Configuration saved in distilbert_multilabel/checkpoint-2838/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-2838/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-3784\n",
      "Configuration saved in distilbert_multilabel/checkpoint-3784/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-3784/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-4730\n",
      "Configuration saved in distilbert_multilabel/checkpoint-4730/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-4730/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-5676\n",
      "Configuration saved in distilbert_multilabel/checkpoint-5676/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-5676/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-6622\n",
      "Configuration saved in distilbert_multilabel/checkpoint-6622/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-6622/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-7568\n",
      "Configuration saved in distilbert_multilabel/checkpoint-7568/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-7568/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-8514\n",
      "Configuration saved in distilbert_multilabel/checkpoint-8514/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-8514/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2523\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-9460\n",
      "Configuration saved in distilbert_multilabel/checkpoint-9460/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-9460/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9460, training_loss=0.0680310230174478, metrics={'train_runtime': 3144.6302, 'train_samples_per_second': 72.199, 'train_steps_per_second': 3.008, 'total_flos': 3.00904160477184e+16, 'train_loss': 0.0680310230174478, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dat[\"train\"],\n",
    "    eval_dataset=dat[\"validation\"],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e78b7b-de25-4279-b7be-4dcfab7822ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T17:35:35.390661Z",
     "iopub.status.busy": "2021-11-30T17:35:35.390378Z",
     "iopub.status.idle": "2021-11-30T17:35:35.399162Z",
     "shell.execute_reply": "2021-11-30T17:35:35.398424Z",
     "shell.execute_reply.started": "2021-11-30T17:35:35.390631Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "\n",
    "dl = DataLoader(dat[\"test\"], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06eb0fb4-fedb-4f7c-977e-9c0924196213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T17:35:35.400411Z",
     "iopub.status.busy": "2021-11-30T17:35:35.400132Z",
     "iopub.status.idle": "2021-11-30T17:36:00.346316Z",
     "shell.execute_reply": "2021-11-30T17:36:00.345617Z",
     "shell.execute_reply.started": "2021-11-30T17:35:35.400382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hamming_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "for batch in dl:\n",
    "    batch = {k: v.to(\"cuda:0\") for k, v in batch.items()}\n",
    "\n",
    "    logits = model(**batch).get(\"logits\")\n",
    "    y_true = batch.get(\"labels\").bool()\n",
    "    y_pred = nn.Sigmoid()(logits) > 0.5\n",
    "\n",
    "    true_pos = logical_and(y_true, y_pred).sum(axis=1)\n",
    "    pred_pos = logical_or(y_true, y_pred).sum(axis=1)\n",
    "\n",
    "    hamming_score = (true_pos / pred_pos).nansum().cpu().item()\n",
    "    precision = (true_pos / y_true.sum(axis=1)).nansum().cpu().item()\n",
    "    recall = (true_pos / y_pred.sum(axis=1)).nansum().cpu().item()\n",
    "\n",
    "    hamming_accuracies.append(hamming_score / y_true.shape[0])\n",
    "    precisions.append(precision / y_true.shape[0])\n",
    "    recalls.append(recall / y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f701f9fe-33c7-46a8-b01b-76f0ddbdd167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T17:36:00.349073Z",
     "iopub.status.busy": "2021-11-30T17:36:00.348798Z",
     "iopub.status.idle": "2021-11-30T17:36:00.354100Z",
     "shell.execute_reply": "2021-11-30T17:36:00.353420Z",
     "shell.execute_reply.started": "2021-11-30T17:36:00.349043Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Hamming accuracy: 0.48030087160772117\n",
      "    Precision: 0.5124152715204162\n",
      "    Recall: 0.5462599597372472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "    Hamming accuracy: {sum([8 * x for x in hamming_accuracies]) / dat[\"test\"].shape[0]}\n",
    "    Precision: {sum([8 * x for x in precisions]) / dat[\"test\"].shape[0]}\n",
    "    Recall: {sum([8 * x for x in recalls]) / dat[\"test\"].shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
