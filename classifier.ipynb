{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d597da-08b5-4ec2-b0eb-2d2b76d3130a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:41.829267Z",
     "iopub.status.busy": "2021-12-01T01:31:41.828376Z",
     "iopub.status.idle": "2021-12-01T01:31:46.404266Z",
     "shell.execute_reply": "2021-12-01T01:31:46.403551Z",
     "shell.execute_reply.started": "2021-12-01T01:31:41.829181Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric\n",
    "from torch import logical_and, logical_or, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e193bb6-f672-4853-8206-e6b0154a83ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:46.405563Z",
     "iopub.status.busy": "2021-12-01T01:31:46.405352Z",
     "iopub.status.idle": "2021-12-01T01:31:46.409529Z",
     "shell.execute_reply": "2021-12-01T01:31:46.408873Z",
     "shell.execute_reply.started": "2021-12-01T01:31:46.405535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "batch_size = 8\n",
    "num_genres = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5281f0f3-657d-49c7-9805-04861b1bfa0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:46.411744Z",
     "iopub.status.busy": "2021-12-01T01:31:46.411386Z",
     "iopub.status.idle": "2021-12-01T01:31:52.923908Z",
     "shell.execute_reply": "2021-12-01T01:31:52.922907Z",
     "shell.execute_reply.started": "2021-12-01T01:31:46.411714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and nest genres\n",
    "df = pd.read_csv(\"data/df_fixed.csv\")\n",
    "df_genres = pd.read_csv(\"data/df_genres.csv\")\n",
    "\n",
    "# Some data cleaning on the Plot\n",
    "regex_fixes = [\n",
    "    [\"\\s*\\[.*\\]\", \" \", True],  # footnotes\n",
    "    [\"–|—\", \"-\", True],  # dash\n",
    "    [\"\\r\\n\", \"\", True],  # newlines\n",
    "]\n",
    "\n",
    "for i, row in enumerate(regex_fixes):\n",
    "    df[\"Plot\"] = df[\"Plot\"].str.replace(row[0], row[1], regex=row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9754a41e-2a38-4fba-81d8-f69dfd72dd95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:52.928251Z",
     "iopub.status.busy": "2021-12-01T01:31:52.928004Z",
     "iopub.status.idle": "2021-12-01T01:31:52.962372Z",
     "shell.execute_reply": "2021-12-01T01:31:52.961747Z",
     "shell.execute_reply.started": "2021-12-01T01:31:52.928218Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge similar genres (see https://aclanthology.org/Y18-1007.pdf)\n",
    "genre_groups = pd.DataFrame(\n",
    "    [\n",
    "        (\n",
    "            \"action\",\n",
    "            [\n",
    "                \"action\",\n",
    "                \"adventure\",\n",
    "                \"sci-fi\",\n",
    "                \"superhero\",\n",
    "                \"sport\",\n",
    "                \"spy\",\n",
    "                \"war\",\n",
    "                \"worldwar-i\",\n",
    "                \"worldwar-ii\",\n",
    "            ],\n",
    "        ),\n",
    "        (\"comedy\", [\"comedy\", \"rom-com\", \"black-comedy\"]),\n",
    "        (\"drama\", [\"drama\", \"fantasy\", \"biodrama\", \"melodrama\"]),\n",
    "        (\"family\", [\"family\", \"animation\", \"musical\", \"anime\", \"child\"]),\n",
    "        (\"thriller\", [\"thriller\", \"mystery\"]),\n",
    "        (\"documentary\", [\"documentary\", \"biographical\", \"historical\"]),\n",
    "    ],\n",
    "    columns=[\"genre_group\", \"Genre\"],\n",
    ").explode(\"Genre\")\n",
    "\n",
    "df_genres = df_genres.merge(genre_groups, how=\"left\", on=\"Genre\")\n",
    "df_genres.loc[df_genres.genre_group.notna(), \"Genre\"] = df_genres[\"genre_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a5e173-c689-4015-81a5-78bb399b2dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:52.963474Z",
     "iopub.status.busy": "2021-12-01T01:31:52.963271Z",
     "iopub.status.idle": "2021-12-01T01:31:53.004208Z",
     "shell.execute_reply": "2021-12-01T01:31:53.003629Z",
     "shell.execute_reply.started": "2021-12-01T01:31:52.963447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['drama', 'comedy', 'action', 'family', 'thriller', 'romance',\n",
       "       'crime', 'horror', 'western', 'documentary'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the top `num_genres` genres\n",
    "top_genres = (\n",
    "    df_genres.query(\"Genre != 'unknown'\")\n",
    "    .groupby(\"Genre\")\n",
    "    .agg(n=(\"Genre\", \"count\"))\n",
    "    .reset_index()\n",
    "    .sort_values(\"n\", ascending=False)\n",
    "    .head(num_genres)\n",
    "    .Genre.values\n",
    ")\n",
    "\n",
    "top_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b13b3e5-3e8f-429d-abb1-6a4a23a1bee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:53.005324Z",
     "iopub.status.busy": "2021-12-01T01:31:53.005116Z",
     "iopub.status.idle": "2021-12-01T01:31:53.113423Z",
     "shell.execute_reply": "2021-12-01T01:31:53.112792Z",
     "shell.execute_reply.started": "2021-12-01T01:31:53.005296Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode genre labels to wide arrays\n",
    "df_genres = (\n",
    "    df_genres.query(\"Genre in @top_genres\")\n",
    "    .assign(cnt=1)\n",
    "    .pivot_table(index=[\"movieID\"], columns=\"Genre\", values=[\"cnt\"])\n",
    "    .fillna(0)\n",
    "    # .astype(int)\n",
    "    .reset_index(col_level=1)  # get movieID out\n",
    ")\n",
    "\n",
    "df_genres.columns = [x[1] for x in df_genres.columns]\n",
    "df_genres = df_genres.set_index(\"movieID\")\n",
    "\n",
    "genre_names = df_genres.columns.tolist()\n",
    "labels = df_genres.values.tolist()\n",
    "df_genres = pd.DataFrame({\"movieID\": df_genres.index, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab835c8-ce1f-48a6-8032-e50f90c0e28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:53.114622Z",
     "iopub.status.busy": "2021-12-01T01:31:53.114410Z",
     "iopub.status.idle": "2021-12-01T01:31:53.175970Z",
     "shell.execute_reply": "2021-12-01T01:31:53.175379Z",
     "shell.execute_reply.started": "2021-12-01T01:31:53.114593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>Plot</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25286</th>\n",
       "      <td>31088</td>\n",
       "      <td>The film opens when a child named Tarun starts...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>8275</td>\n",
       "      <td>Rancher Taw Jackson (John Wayne) returns to hi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48</td>\n",
       "      <td>Only lasting 15 minutes, it is a light-hearted...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>17538</td>\n",
       "      <td>Jake Cullen (Bill Kerr) is babysitting his gra...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>12110</td>\n",
       "      <td>Christina Ford (Bo Derek) a beautiful woman, i...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13311</th>\n",
       "      <td>14398</td>\n",
       "      <td>A team of researchers funded by a New York pha...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>19430</td>\n",
       "      <td>Ewan McEwan, an easy-going sheep and corn farm...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>3198</td>\n",
       "      <td>Ted Scott (John Payne) is a band pianist whose...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>7578</td>\n",
       "      <td>Two American World War II veterans Jeff (John ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>7608</td>\n",
       "      <td>Nick Adams is a young, restless man who wants ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieID                                               Plot  \\\n",
       "25286    31088  The film opens when a child named Tarun starts...   \n",
       "7595      8275  Rancher Taw Jackson (John Wayne) returns to hi...   \n",
       "28          48  Only lasting 15 minutes, it is a light-hearted...   \n",
       "16275    17538  Jake Cullen (Bill Kerr) is babysitting his gra...   \n",
       "11099    12110  Christina Ford (Bo Derek) a beautiful woman, i...   \n",
       "13311    14398  A team of researchers funded by a New York pha...   \n",
       "18078    19430  Ewan McEwan, an easy-going sheep and corn farm...   \n",
       "3082      3198  Ted Scott (John Payne) is a band pianist whose...   \n",
       "6926      7578  Two American World War II veterans Jeff (John ...   \n",
       "6953      7608  Nick Adams is a young, restless man who wants ...   \n",
       "\n",
       "                                                  labels  \n",
       "25286  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7595   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "28     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "16275  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...  \n",
       "11099  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13311  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "18078  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3082   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "6926   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6953   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.reset_index()\n",
    "    .rename(columns={\"index\": \"movieID\"})\n",
    "    .filter([\"movieID\", \"Plot\"])\n",
    "    .merge(df_genres, on=\"movieID\")\n",
    ")\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639006f-5c09-44eb-a446-3af9a77c9684",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad553cfe-57cd-45ef-98c8-acc26f3b1e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:31:53.177172Z",
     "iopub.status.busy": "2021-12-01T01:31:53.176960Z",
     "iopub.status.idle": "2021-12-01T01:32:03.956592Z",
     "shell.execute_reply": "2021-12-01T01:32:03.955908Z",
     "shell.execute_reply.started": "2021-12-01T01:31:53.177144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4adc6d6c1b4d9999ff53737277412c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Construct dataset\n",
    "dat = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize the Plot column\n",
    "dat = dat.map(\n",
    "    lambda batch: tokenizer.batch_encode_plus(\n",
    "        batch[\"Plot\"], padding=\"max_length\", truncation=True\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=[\"__index_level_0__\", \"movieID\"],\n",
    ")\n",
    "\n",
    "# Retrieve tensors of the following columns as model inputs\n",
    "valid_cols = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    "cols = [c for c in dat.column_names if c in valid_cols]\n",
    "dat.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "# Train/validation/test split\n",
    "dat = dat.train_test_split(test_size=test_ratio, seed=42)\n",
    "dat_train = dat[\"train\"].train_test_split(test_size=val_ratio, seed=42)\n",
    "dat[\"train\"] = dat_train[\"train\"]\n",
    "dat[\"validation\"] = dat_train[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1d4f9a-0c15-4460-9904-60cf2910a004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:32:03.957975Z",
     "iopub.status.busy": "2021-12-01T01:32:03.957697Z",
     "iopub.status.idle": "2021-12-01T01:32:10.025357Z",
     "shell.execute_reply": "2021-12-01T01:32:10.024482Z",
     "shell.execute_reply.started": "2021-12-01T01:32:03.957944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify last layer of model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, problem_type=\"multi_label_classification\", num_labels=num_genres\n",
    ")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ecf802d-b150-46cb-97a1-8e5513de9014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:32:10.027128Z",
     "iopub.status.busy": "2021-12-01T01:32:10.026886Z",
     "iopub.status.idle": "2021-12-01T01:32:10.034291Z",
     "shell.execute_reply": "2021-12-01T01:32:10.033518Z",
     "shell.execute_reply.started": "2021-12-01T01:32:10.027093Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert_multilabel\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=1,  # make sure validation loss is logged in each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "074894a7-27ba-461a-a3b0-961c997f64b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:32:10.035421Z",
     "iopub.status.busy": "2021-12-01T01:32:10.035214Z",
     "iopub.status.idle": "2021-12-01T01:47:53.733566Z",
     "shell.execute_reply": "2021-12-01T01:47:53.732839Z",
     "shell.execute_reply.started": "2021-12-01T01:32:10.035394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Plot.\n",
      "***** Running training *****\n",
      "  Num examples = 22277\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2787\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2787' max='2787' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2787/2787 15:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.227829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.210961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.211835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Plot.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2476\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-929\n",
      "Configuration saved in distilbert_multilabel/checkpoint-929/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-929/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Plot.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2476\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-1858\n",
      "Configuration saved in distilbert_multilabel/checkpoint-1858/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-1858/pytorch_model.bin\n",
      "/opt/conda/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: Plot.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2476\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to distilbert_multilabel/checkpoint-2787\n",
      "Configuration saved in distilbert_multilabel/checkpoint-2787/config.json\n",
      "Model weights saved in distilbert_multilabel/checkpoint-2787/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2787, training_loss=0.22178466243527037, metrics={'train_runtime': 943.6196, 'train_samples_per_second': 70.824, 'train_steps_per_second': 2.954, 'total_flos': 8854191754905600.0, 'train_loss': 0.22178466243527037, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dat[\"train\"],\n",
    "    eval_dataset=dat[\"validation\"],\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e78b7b-de25-4279-b7be-4dcfab7822ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:47:53.736610Z",
     "iopub.status.busy": "2021-12-01T01:47:53.736395Z",
     "iopub.status.idle": "2021-12-01T01:47:53.744574Z",
     "shell.execute_reply": "2021-12-01T01:47:53.744017Z",
     "shell.execute_reply.started": "2021-12-01T01:47:53.736581Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")\n",
    "model.eval()\n",
    "\n",
    "dl = DataLoader(dat[\"test\"], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefcbadd-abb9-4279-aaf2-b0f80a717b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:47:53.747758Z",
     "iopub.status.busy": "2021-12-01T01:47:53.747504Z",
     "iopub.status.idle": "2021-12-01T01:48:18.467913Z",
     "shell.execute_reply": "2021-12-01T01:48:18.466845Z",
     "shell.execute_reply.started": "2021-12-01T01:47:53.747730Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "proba_labels = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "for batch in dl:\n",
    "    batch = {k: v.to(\"cuda:0\") for k, v in batch.items()}\n",
    "    logits = model(**batch).get(\"logits\")\n",
    "\n",
    "    # Make sure there's at least one predicted label\n",
    "    # by setting the logit of the maximum to 10\n",
    "    max_proba = logits.argmax(axis=1)\n",
    "    for i in range(logits.shape[0]):\n",
    "        logits[i, max_proba[i]] = 10.0\n",
    "\n",
    "    y_pred = (sigmoid(logits) > 0.5).cpu().detach().numpy()\n",
    "    proba_labels.append(y_pred)\n",
    "\n",
    "proba_labels = np.vstack(proba_labels)\n",
    "y_labels = dat[\"test\"][\"labels\"].bool().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b22377-c5ed-4054-8aae-adb00ec4ba41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:48:18.471779Z",
     "iopub.status.busy": "2021-12-01T01:48:18.471506Z",
     "iopub.status.idle": "2021-12-01T01:48:18.491999Z",
     "shell.execute_reply": "2021-12-01T01:48:18.491404Z",
     "shell.execute_reply.started": "2021-12-01T01:48:18.471748Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      action       0.65      0.64      0.64       514\n",
      "      comedy       0.76      0.54      0.63       740\n",
      "       crime       0.46      0.31      0.37       154\n",
      " documentary       0.67      0.19      0.29        74\n",
      "       drama       0.61      0.70      0.65       969\n",
      "      family       0.75      0.43      0.54       257\n",
      "      horror       0.67      0.71      0.69       172\n",
      "     romance       0.53      0.32      0.40       201\n",
      "    thriller       0.50      0.30      0.37       228\n",
      "     western       0.88      0.86      0.87        97\n",
      "\n",
      "   micro avg       0.65      0.56      0.60      3406\n",
      "   macro avg       0.65      0.50      0.55      3406\n",
      "weighted avg       0.65      0.56      0.59      3406\n",
      " samples avg       0.66      0.60      0.61      3406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_labels, proba_labels, target_names=genre_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cdf8273-7a76-46d2-ad90-a204c2578e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:48:18.493089Z",
     "iopub.status.busy": "2021-12-01T01:48:18.492886Z",
     "iopub.status.idle": "2021-12-01T01:48:18.500813Z",
     "shell.execute_reply": "2021-12-01T01:48:18.500227Z",
     "shell.execute_reply.started": "2021-12-01T01:48:18.493062Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Hamming accuracy: 0.5784684357203441\n",
      "    Precision: 0.6006906579425664\n",
      "    Recall: 0.6572155579789167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_pos = np.logical_and(y_labels, proba_labels).sum(axis=1)\n",
    "pred_pos = np.logical_or(y_labels, proba_labels).sum(axis=1)\n",
    "\n",
    "hamming_score = np.nansum(true_pos / pred_pos) / y_labels.shape[0]\n",
    "precision = np.nansum(true_pos / y_labels.sum(axis=1)) / y_labels.shape[0]\n",
    "recall = np.nansum(true_pos / proba_labels.sum(axis=1)) / y_labels.shape[0]\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "    Hamming accuracy: {hamming_score}\n",
    "    Precision: {precision}\n",
    "    Recall: {recall}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40b1995c-16dd-4a8b-ad0c-e576a37edda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-01T01:48:18.501889Z",
     "iopub.status.busy": "2021-12-01T01:48:18.501687Z",
     "iopub.status.idle": "2021-12-01T01:48:18.684693Z",
     "shell.execute_reply": "2021-12-01T01:48:18.684050Z",
     "shell.execute_reply.started": "2021-12-01T01:48:18.501863Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    True label: ['action']\n",
      "    Predicted label: ['action']\n",
      "    Plot: A British naval officer volunteers for a dangerous mission to infiltrate the base of pirates who threaten shipping off Madagascar.\n",
      "    \n",
      "\n",
      "    True label: ['comedy']\n",
      "    Predicted label: ['comedy']\n",
      "    Plot: The film starts off with Calvin \"Babyface\" Simms (Marlon Wayans) who is a very short convict. He is seen getting released and planning a robbery to steal a diamond with the help of his goofball cohort Percy (Tracy Morgan). After the successful robbery, the duo are almost arrested, but not before Calvin manages to stash the diamond in a nearby woman's purse. The thieves follow the handbag's owner to her home where they discover a couple, Darryl (Shawn Wayans) and Vanessa Edwards (Kerry Washington), who are eager to have a child.Calvin and Percy hatch a plot to pass Calvin off as a baby left on the couple's doorstep. After seeing Calvin, Darryl and Vanessa, wanting a child, immediately adopt the baby as their own. However, Vanessa's dad Francis \"Pops\" (John Witherspoon) has a bad feeling about Calvin. Friends of the couple find Calvin odd as well. Soon, Calvin warms up to the family. A local goon named Walken (Chazz Palminteri), discovers the deception and demands the diamond from Percy. Percy arrives at the house that Calvin is staying in, and convinces Walken's henchmen that Darryl is his partner. Walken and his henchmen go to the house and they keep Calvin and Darryl hostage. In a series of comedic maneuvers, Calvin manages to rescue Darryl and have Walken arrested. Darryl is given a substantial reward for the recovery of the diamond, and since Calvin saved his life, he doesn't turn him over to the police.Before he leaves, Calvin thanks Darryl for taking care of him even though he wasn't really a baby and admits that he thinks Darryl would make a great father for a real child someday. Calvin is about to be out of Darryl's life for good, as Darryl watches him leave. Calvin is crying hysterically, so Darryl decides to let Calvin stay and from that point on, the two men become the best of friends. The film ends at some point in the future with Calvin and Pops playing with Darryl and Vanessa's real baby, who looks exactly like Darryl (Shawn Wayans' face superimposed on that of the baby). And they all lived happily ever after.\n",
      "    \n",
      "\n",
      "    True label: ['action']\n",
      "    Predicted label: ['action', 'drama']\n",
      "    Plot: 8 months after triumphing over Serizawa Tamao (Takayuki Yamada), Takiya Genji (Shun Oguri) still struggles to attain supremacy at Suzuran All-Boys High School. Following a decisive defeat at the hands of the legendary Rindaman, and on the verge of graduating without fulfilling his goal, Genji grows quietly desperate. He begins challenging Rindaman regularly, but consistently fails to beat him. His situation escalates when he unwittingly breaks a non-aggression pact between Suzuran and a rival school, Housen Academy, by coming to the aid of Kawanishi Noboru (Shinnosuke Abe) during a heated confrontation. Genji learns that the agreement between the two schools was established two years prior when, during a skirmish, Noboru violated a gang law and used a weapon to fatally wound Housen's former leader, Bitō Makio. Suzuran had subsequently sworn not to interfere with Housen's retribution upon Noboru's release from prison. Genji's protection of Kawanishi provokes Housen's current leader, Narumi Taiga (Nobuaki Kaneko), to declare war against Suzuran. Genji and his allies go on the defensive, engaging in several violent conflicts with Housen's \"Army of Killers\".\n",
      "    \n",
      "\n",
      "    True label: ['comedy']\n",
      "    Predicted label: ['comedy']\n",
      "    Plot: Several railroad workers discover a yogurt-like white substance bubbling out of the ground. These workers find it to be sweet and addictive. Later, the substance, marketed as \"The Stuff,\" is being sold to the general public in containers like ice cream. It is marketed as having no calories and as being sweet, creamy, and filling. The Stuff quickly becomes a nationwide craze and drastically hurts the sales of ice cream.Former FBI agent turned industrial saboteur David \"Mo\" Rutherford is hired by the leaders of the suffering ice cream industry, as well as junk food mogul Charles W. \"Chocolate Chip Charlie\" Hobbs, to find out exactly what The Stuff is and destroy it.Under their commissions, Rutherford conducts an investigation into The Stuff. His efforts reveal, to his initial horror, that the craze for the dessert is far deadlier than anyone had believed: The Stuff is actually a living, parasitic, and possibly sentient organism that gradually takes over the brain; it then mutates those who eat it into bizarre zombie-like creatures, before consuming them from the inside and leaving them literal empty shells of their former selves.A young boy named Jason also discovers The Stuff is alive and sees how it affects his family and how they are adamant towards his beliefs on The Stuff. He gets arrested for vandalizing a supermarket display of The Stuff, attracting the attention of Rutherford, who comes to his aid. Rutherford also manages to charm Nicole, an advertising executive who becomes his partner and lover when she sees the effect of The Stuff. The trio infiltrates the distribution operation, which is actually an organized corporate effort to spread The Stuff on the basis of eliminating world hunger, and destroy the lake of The Stuff with explosives. Meanwhile, United States Army Col. Malcolm Grommett Spears, a retired right-wing soldier, leads a militia in battling the zombies and transmitting a civil defense message for Americans to break their addiction to The Stuff by destroying it with fire. The Stuff addiction is ended, and Rutherford, Nicole, Jason, and Col. Spears are hailed as national heroes.Mo then visits the head of The Stuff Company, a man named Mr. Fletcher. He tells Mo that the destruction of the mine has not hurt his business, since The Stuff seeps out from many places in the ground, but Mo vows to find those places and get rid of them all. Another man, Mr. Vickers, brings in Mr. Evans, the ice cream mogul with whom he is now working--and who had originally hired Mo to find out about what The Stuff was. They tell him they have come up with a new product that they call \"The Taste,\" which is a mix of 88% ice cream and 12% The Stuff, supposedly enough to make people crave more without it taking over their minds or killing them. However, Mo then brings in Jason, who is carrying a box, and then holds the two moguls at gunpoint. The box is full of pint containers of The Stuff, and Mo forces both to eat them all as punishment for all the lives lost to it, and for their greed. As they do, Rutherford asks pointedly, \"Are you eating it...or is it eating YOU?\" When they finish, Mo and Jason leave them to the approaching police.The film ends with smugglers selling The Stuff on the black market, having one of the smugglers tasting The Stuff, and revealing that samples of The Stuff still exist. In a post-credits scene, a woman in a bathroom says \"Enough is never enough\" while holding The Stuff.\n",
      "    \n",
      "\n",
      "    True label: ['action', 'drama']\n",
      "    Predicted label: ['action']\n",
      "    Plot: Professor Chakravarty and his wife Uma (Achala Sachdev) live with their four-year-old son in the jungle where he carries out experiments. He has discovered the formula to prevent ageing. Adversity strikes when their house is attacked by lions, killing him, while his wife goes mad with grief. The professor's son goes missing in the melee. The story then follows the arrival of several people seventeen years later from the city. One of them is the Professor's brother who has traveled to the jungle with his daughter in search of the missing formula and to look for the professor's son. There are villains in the group of people, wanting the formula for their own purposes. Chakravarty's son Zimbo has been brought up by the apes and the story takes a turn when they try to relocate him with Dada (Pedro the Chimpanzee) to the city.\n",
      "    \n",
      "\n",
      "    True label: ['horror']\n",
      "    Predicted label: ['horror']\n",
      "    Plot: Each spring, a party from a fort travels to Hudson Bay to trade pelts for winter provisions, but, in 1815, nobody returns.Brigitte and Ginger are lost with their horse in the Canadian wilderness when they come across a seemingly abandoned camp. An elderly Indian woman, who warns them that they must kill a boy to prevent one sister from killing the other, gives them each a pendant. As their startled horse runs off, Brigitte's foot is caught in a trap. Ginger seeks help, but the hunter frees Brigitte before she returns. He leads them to Fort Bailey, where they take refuge. Ginger says they are the daughters of a drowned trader and are seeking passage east.Werewolves have besieged the fort for some time. Murphy, the fort's physician, inspects Brigitte’s wound and applies a leech, surreptitiously testing for werewolf infection. They are given a room that belonged to Wallace's son. Awakened by a voice, Ginger investigates the corridors, where she eventually finds the source: a deformed boy kept in a small, bolted unlit room; he bites her shoulder as he flees.When Ginger and Brigitte attempt to leave, James confronts them. While Ginger and James are fighting, werewolves attack, killing one of the residents. Reverend Gilbert leads the sisters to an allegedly safe building, which actually contains a werewolf. The sisters run up the stairs, chased by the werewolf, but the hunter appears and kills it. As Ginger and Brigitte are going to their room Ginger's nose starts to bleed; a sign that she is infected.The sisters discover the boy who bit Ginger is Wallace's son, Geoffrey. As Ginger sleeps, he sneaks into the bedroom and wakes her. She tries to grab him, but he gets away, taking a lock of her hair; Geoffrey then kills a man who investigates the noise, and frames Ginger for his murder. James holds Brigitte captive as the others drag Ginger away. Wallace arrives, dismisses James, and makes a deal with Brigitte: her sister's life in exchange for their silence regarding his son. Wallace and Brigitte find Ginger at the doctor's, strapped to the examination table and held at gunpoint, about to be tested with a leech. When Wallace demands they release Ginger, Murphy ignores the order. Wallace shoots him dead, which prompts the other men to leave.Determined to kill Geoffrey, Ginger finds him as he cries at his mother's grave. He escapes and is captured instead by the men. Wallace arrives and kills his son himself. The sisters' protection at an end, Ginger is forced to leave, and Brigitte goes with her. Desperate for a cure, the sisters go to the hunter's cave, and Ginger kills their guide shortly before they arrive.At the cave, the hunter and Indian seer woman reveal the sisters' coming had long been prophesied and that the Red and the Black would decide the destiny of the werewolf bloodline. After Brigitte enters a trance-like state, she has a vision of her destiny - the hunter attempts to kill Ginger, and she kills her sister herself. As Brigitte emerges from the trance she finds the seer is dead, killed by Ginger, who has fled. The hunter leads Brigitte back to the fort.Back at the fort, Brigitte is taken prisoner. Gilbert tells her to beg forgiveness, but she spits in his face. Gilbert drags her out onto the parade square and prepares to burn her alive. Wallace interrupts him, runs Gilbert through with his sword, and sets him on fire. James engages Ginger in a fight, and she slashes his throat. As he falls to the ground, Ginger opens the gates and ushers in the werewolves. While the hunter holds his own against them, Wallace is soon bitten and sets the fort on fire before killing himself. The hunter urges Brigitte to kill her sister; instead, Brigitte kills the hunter and flees with her sister.The film ends with only Ginger and Brigitte left alive huddled in the snow. When Brigitte says that she is cold, Ginger says that she is not. Brigitte then holds out her hand and presses a cut on it against a cut on Ginger's hand - mingling their blood and infecting Brigitte.\n",
      "    \n",
      "\n",
      "    True label: ['comedy', 'romance']\n",
      "    Predicted label: ['comedy']\n",
      "    Plot: A pair of brides-to-be put their friendship to the test when they battle it out for the perfect wedding scheduled on the same day.\n",
      "    \n",
      "\n",
      "    True label: ['action', 'drama', 'family']\n",
      "    Predicted label: ['drama']\n",
      "    Plot: Former Olympic medallist boxer Baldev Choudhary (Dharmendra) is disgraced while competing for the World Heavy weight championship when a betting syndicate falsely accuses him of drug doping. He tries to erase this stain upon his honour by training up his son, Angad (Sunny Deol) but financial difficulties keep them from achieving his dream. He trains a local boy to get into a media hyped TV boxing show, but is dropped for a better coach at the last minute. Baldev's younger son Karan (Bobby Deol) has just launched his first music album. Realising his father is depressed, he gives up his own dream of a musical career to become a boxer and please his father. Karan persists with training and wins a series of fights, thinking that victory will bring his family together. The final match is with the current world heavy champion; Karan is tricked and he ends up paralysed in a hospital bed. Baldev, who wanted to wash a stigma is now about to lose his son. When Karan reveals the world heavy champion cheated, Angad decides to return to boxing and win the title for his father. He eventually brings the world heavyweight champion belt to India in triumph, however meanwhile Karan suffers liver damage and requires a liver to survive. A guilt stricken Baldev pleads with the doctors to use his liver, but the doctors reject the idea. In a stroke of luck, a liver is given to Karan through an unknown donor. In the end, Baldev who was going to give up his life for Karan, is instead alive and happy with his family.\n",
      "    \n",
      "\n",
      "    True label: ['comedy']\n",
      "    Predicted label: ['comedy']\n",
      "    Plot: Old Mother Riley does the laundry for the dancers in the pantomime \"Aladdin\", where her daughter Kitty works as a chorus girl. Sneaking a peek at the show one day, Mother Riley accidentally pops up through a trap door onto the stage. Accosted by the angry star, Mother Riley’s belligerent responses have the audience in stitches. Outraged, the star walks out, leaving Kitty to take over the leading role, to great success. Kitty is congratulated after the show by wealthy high society boy Tony Morgan, and the couple start to fall in love. Tony and Kitty eventually marry and move into the Morgan family mansion, taking Mother Riley with them, as Kitty’s personal maid. During a swanky party to introduce Kitty to Tony's upper class friends, rumours start up about Kitty’s former stage career. Kitty is about to confess her past, but Mother Riley - fearing this will have damaging effect on her daughter’s social standing - causes a disruption, then leaves a goodbye note and vanishes. Kitty tells Tony the truth, and the couple hire a detective to trace Mother Riley, but without success. Mother Riley works her way through a variety of dead end jobs after separating from Kitty, and ends up living in a dingey hostel and picking up degrading casual work as a dishwasher. A chance encounter with old friend Tug Mulligan results in her reunion with Kitty; Tony’s family explains they’re not \"high society\" after all, merely \"nouveau riche\". \"We made our money in sausages\", declares Lady Morgan; \"then we're all friends together\", replies Mother Riley. \n",
      "    \n",
      "\n",
      "    True label: ['documentary', 'drama']\n",
      "    Predicted label: ['drama']\n",
      "    Plot: In New York City in the fall of 1937, 17-year-old high-school student Richard Samuels meets Orson Welles, who unexpectedly offers him the role of Lucius in Caesar, the first production of his new Mercury Theatre repertory company. The company is immersed in rehearsals at its Broadway theater. Charmed by Welles, Richard infers that he is having an affair with the leading actress while his wife is pregnant. Richard finds ambitious production assistant Sonja Jones is attracted to him.Welles tells Richard a few days before the premiere that he is worried, because he has recently had nothing but good luck; he fears that he will finally have bad luck with the premiere, and that the play will be a flop. During rehearsals Richard accidentally sets off the sprinkler system, soaking the entire theatre. When accused by Welles he denies having anything to do with the deluge, and suggests that the catastrophe was the bad luck that Welles needed to get out of the way.Welles decides the entire production crew would benefit from a coupling game, and Richard cheats to ensure he is paired with Sonja. Richard spends the night with Sonja, but becomes jealous when she spends the next night with Welles. He confronts Welles, mentions his pregnant wife, and is fired. An apparent reconciliation follows, and Richard performs on the first night. The anti-fascist adaptation of Caesar is a huge success, but after the premiere, Richard is told that Welles only needed him in order to secure a successful first-night production and, that done, he has again been fired.The broken-hearted but wiser Richard spontaneously recites lines from Julius Caesar in his high school English class, to his classmates' applause. He later meets up with a likely new girlfriend, Gretta Adler, a young aspiring playwright whom he met in a music store at the film's beginning. With Richard's and Sonja's assistance, Adler manages to get a story published in The New Yorker, and she invites Richard out, to help her celebrate.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Get genre names and plot text\n",
    "true_labels = [\n",
    "    [genre_names[x] for x in np.argwhere(arr == 1).flatten()] for arr in y_labels\n",
    "]\n",
    "plots = dat[\"test\"][\"Plot\"]\n",
    "pred_labels = [\n",
    "    [genre_names[x] for x in np.argwhere(arr == 1).flatten()] for arr in proba_labels\n",
    "]\n",
    "\n",
    "for i in range(10):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    True label: {true_labels[i]}\n",
    "    Predicted label: {pred_labels[i]}\n",
    "    Plot: {plots[i]}\n",
    "    \"\"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
